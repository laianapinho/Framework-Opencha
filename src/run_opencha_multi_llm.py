#!/usr/bin/env python3
"""
openCHA + Multi-LLM - Teste Simples (CORRIGIDO)
Compare ChatGPT, Gemini e DeepSeek lado a lado

‚úÖ CORRE√á√ÉO: Pr√©-inicializa os modelos ANTES de abrir a interface
   Evita race condition e APIConnectionError
"""
from openCHA import openCHA

def main():
    print("üî∑ openCHA + Multi-LLM")
    print("=" * 50)

    # Cria o agente com Multi-LLM habilitado
    cha = openCHA(
        name="openCHA-MultiLLM",
        verbose=False,

        # Configura√ß√µes Multi-LLM
        multi_llm_enable_cache=True,
        multi_llm_timeout=180,
        multi_llm_max_workers=3,
    )

    print("üåê Pr√©-inicializando modelos...")
    print("-" * 50)

    # ‚úÖ CORRE√á√ÉO: For√ßa inicializa√ß√£o ANTES de abrir a interface
    # Isso evita race condition quando a interface tenta usar os modelos
    try:
        manager = cha.get_multi_llm()
        modelos_disponiveis = manager.get_available_models()
        print(f"‚úÖ Modelos prontos: {', '.join(modelos_disponiveis)}")
        print(f"‚úÖ Total: {len(modelos_disponiveis)} modelo(s) inicializado(s)")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro na pr√©-inicializa√ß√£o: {e}")
        print("   Tentando continuar mesmo assim...")

    print("-" * 50)
    print()

    print("üåê Iniciando interface web...")
    print("üìç URL: http://localhost:7860")
    print("ü§ñ Modelos: ChatGPT | Gemini | DeepSeek")
    print("‚ú® Modo: Compara√ß√£o Multi-LLM")
    print("üõë Para parar: Ctrl+C")
    print("=" * 50)
    print()
    print("üí° Como usar:")
    print("  1. Configure suas API keys na interface")
    print("  2. Ative 'Modo Multi-LLM' no accordion")
    print("  3. Selecione os modelos para comparar")
    print("  4. Digite sua pergunta!")
    print()

    try:
        cha.run_with_interface()
    except KeyboardInterrupt:
        print("\nüëã openCHA encerrado")

if __name__ == "__main__":
    main()
