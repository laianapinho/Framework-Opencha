#!/usr/bin/env python3
"""
openCHA + Benchmark FlexÃ­vel - Com OrquestraÃ§Ã£o
Teste 3 modelos com qualquer dataset JSON (PubMedQA, CareQA, customizado, etc)
"""
import sys
sys.path.insert(0, '/home/laiana/Framework-Opencha/src')
import os
from openCHA.openCHA import openCHA
from openCHA.benchmark_interface import BenchmarkInterface


def main():
    print("ğŸ“Š openCHA + Benchmark FlexÃ­vel (Qualquer Dataset JSON)")
    print("=" * 70)

    # Cria o agente com orquestraÃ§Ã£o
    cha = openCHA(
        name="openCHA-Benchmark",
        verbose=False,
        multi_llm_enable_cache=True,
        multi_llm_timeout=180,
        multi_llm_max_workers=3,
    )

    print("ğŸŒ Iniciando interface web...")
    print("ğŸ“ URL: http://localhost:7860")
    print("ğŸ¤– Modelos: ChatGPT | Gemini | DeepSeek")
    print("âœ¨ Modo: Benchmark FlexÃ­vel (upload qualquer JSON)")
    print("ğŸ“ Suporta: PubMedQA, CareQA, e qualquer estrutura JSON customizada")
    print("ğŸ›‘ Para parar: Ctrl+C")
    print("=" * 70)
    print()

    try:
        from openCHA.interface import Interface
        from openCHA.tasks import TASK_TO_CLASS
        import gradio as gr

        interface = Interface()
        respond = cha.respond
        reset = cha.reset
        upload_meta = cha.upload_meta
        available_tasks = [key.value for key in TASK_TO_CLASS.keys()]

        with gr.Blocks(theme=gr.themes.Soft(), title="openCHA - Benchmark FlexÃ­vel") as demo:
            gr.Markdown("# ğŸ”· openCHA + Benchmark FlexÃ­vel")
            gr.Markdown("### ğŸ“Š Avalie qualquer dataset JSON com 3 modelos em paralelo")

            with gr.Accordion("ğŸ”‘ API Keys", open=True):
                with gr.Row():
                    openai_key = gr.Textbox(label="OpenAI", type="password")
                    gemini_key = gr.Textbox(label="Gemini", type="password")
                    deepseek_key = gr.Textbox(label="DeepSeek", type="password")
                    serp_key = gr.Textbox(label="SERP", type="password")

            with gr.Tabs():
                # ABA 1: Chat Normal
                with gr.Tab("ğŸ’¬ Chat"):
                    msg = gr.Textbox(placeholder="Digite mensagem...")
                    btn = gr.Button("Enviar")
                    output = gr.Textbox(interactive=False, lines=10)

                # ABA 2: Benchmark FlexÃ­vel
                with gr.Tab("ğŸ“Š Benchmark FlexÃ­vel"):
                    gr.Markdown("""
                    ### ğŸš€ Como usar:
                    1. **Upload**: Selecione um arquivo JSON com suas perguntas e respostas
                    2. **DetecÃ§Ã£o**: O sistema detecta automaticamente a estrutura do JSON
                    3. **ConfirmaÃ§Ã£o**: Confirme ou edite o mapeamento de campos
                    4. **Benchmark**: Execute a avaliaÃ§Ã£o com os 3 modelos

                    ### âœ… Formatos suportados:
                    - **PubMedQA**: `{"QUESTION": "...", "final_decision": "yes/no/maybe"}`
                    - **CareQA**: `[{"question": "...", "answer": "..."}, ...]`
                    - **Customizado**: Qualquer JSON com pergunta e resposta esperada
                    """)

                    benchmark = BenchmarkInterface()
                    benchmark.prepare_benchmark_tab(
                        run_single_question=cha.run,
                        reset_fn=reset
                    )

        demo.launch(share=False, server_port=7860)

    except KeyboardInterrupt:
        print("\nğŸ‘‹ Benchmark encerrado")
    except Exception as e:
        print(f"âŒ Erro: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
